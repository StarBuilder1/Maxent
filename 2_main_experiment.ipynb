{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "/*\n",
    "* author: Yuzhou Chen\n",
    "* date: 2024-07\n",
    "* note: The code blocks should not be executed sequentially, but should follow specific manner according to the purpose of simulation.\n",
    "*/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maxent Simulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **0. Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## necessary R packages ##\n",
    "## R version 4.4.1 ##\n",
    "library('dismo')\n",
    "library(raster)\n",
    "library(sf)\n",
    "library(sp)\n",
    "library(GGally)\n",
    "library(ggplot2)\n",
    "library(glue)\n",
    "library(here)\n",
    "\n",
    "library(patchwork)  #figure stitching\n",
    "library(viridis) #color palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Display predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Read Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## read predictors ##\n",
    "# 3 parts: climate factor, DEM, derived factor\n",
    "tif_folder_paths <- c(\"E:/Working/Sam/Experiment/Data/Alps/ClimateFactor\",\n",
    "                      \"E:/Working/Sam/Experiment/Data/Alps/DEM\",\n",
    "                      \"E:/Working/Sam/Experiment/Data/Alps/Derived_Factor\")\n",
    "fnames <- lapply(tif_folder_paths,\n",
    "function(folder_path) {\n",
    "  list.files(path = folder_path, \n",
    "  pattern = '\\\\.tif$',\n",
    "  full.names = TRUE, recursive = TRUE)\n",
    "})\n",
    "fnames <- unlist(fnames)\n",
    "if (length(fnames) == 0) {\n",
    "  stop(\"No .tif files found in this folder! Please check the folder path.\")\n",
    "}\n",
    "# print(fnames)\n",
    "# Use 'stack' to stack all the grids\n",
    "predictors <- stack(fnames)\n",
    "plot(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Visualize Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## visualize predictors ##\n",
    "save_path = \"E:/Working/Sam/Experiment/Figures/Predictors.tif\"\n",
    "\n",
    "# list to store subplots\n",
    "layer_names <- gsub(pattern = \".*/|\\\\.tif$\", replacement = \"\", x = fnames)\n",
    "plots <- list()\n",
    "\n",
    "# create ggplot objects for each layer\n",
    "for (i in 1:nlayers(predictors)) {\n",
    "  layer_df <- as.data.frame(rasterToPoints(predictors[[i]]))\n",
    "  colnames(layer_df) <- c(\"x\", \"y\", \"value\")\n",
    "  \n",
    "  p <- ggplot(layer_df, aes(x = x, y = y, fill = value)) +\n",
    "    geom_tile() +  # use geom_tile to plot raster data\n",
    "    scale_fill_viridis_c() +\n",
    "    coord_equal() +\n",
    "    theme_minimal() +\n",
    "    labs(title = layer_names[i]) +\n",
    "    theme(legend.position = \"bottom\",\n",
    "    legend.title = element_blank(),\n",
    "    legend.text = element_text(size = 6),    # legend text size\n",
    "    legend.key.size = unit(0.3, \"cm\"),\n",
    "    plot.title = element_text(size = 9, face = \"bold\"),\n",
    "    axis.text.x = element_text(size = 7),\n",
    "    axis.text.y = element_text(size = 7),\n",
    "    axis.title.x = element_blank(),\n",
    "    axis.title.y = element_blank()\n",
    ") +\n",
    "    scale_x_continuous(labels = scales::number_format(accuracy = 1, suffix = \"°\")) +\n",
    "    scale_y_continuous(labels = scales::number_format(accuracy = 1, suffix = \"°\"))\n",
    "  \n",
    "  # add plot to list\n",
    "  plots[[i]] <- p\n",
    "}\n",
    "\n",
    "# stitch plots together\n",
    "combined_plot <- wrap_plots(plots, nrow = 3, ncol = 4)\n",
    "\n",
    "# save plots\n",
    "ggsave(save_path, plot = combined_plot, dpi = 400, width = 9, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Correlationship of Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Correlation analysis ## \n",
    "predictors_df <- as.data.frame(values(predictors))\n",
    "# draw scatterplot matrix\n",
    "# bar chart(self-defined)\n",
    "my_bar <- function(data, mapping, ...) {\n",
    "  ggplot(data, mapping) +\n",
    "    geom_histogram(color = \"blue\", fill = \"blue\", bins = 15)\n",
    "}\n",
    "\n",
    "# scatter chart(self-defined)\n",
    "my_scatter <- function(data, mapping, ...) {\n",
    "  ggplot(data, mapping) +\n",
    "    geom_point(color = \"red\", alpha = 0.2, size = 1.5) +\n",
    "    geom_smooth(method = \"lm\", color = \"black\", ...)\n",
    "}\n",
    "\n",
    "# draw ggpairs plot\n",
    "p <- ggpairs(\n",
    "  predictors_df,\n",
    "  lower = list(continuous = wrap(my_scatter)),\n",
    "  diag = list(continuous = wrap(my_bar)),\n",
    "  upper = list(continuous = wrap(\"cor\", size = 5))\n",
    ")\n",
    "\n",
    "# title\n",
    "p <- p + ggtitle(\"Scatterplot matrix for Predictors\") +\n",
    "  theme(\n",
    "    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n",
    "    # axis.text.x = element_text(angle = 45, hjust = 1, size = 12),\n",
    "    # axis.text.y = element_text(size = 12),\n",
    "    # strip.text = element_text(size = 14),\n",
    "    # text = element_text(size = 12),\n",
    "    # panel.grid.major = element_line(size = 0.5),\n",
    "    # plot.margin = margin(1, 1, 1, 1, \"cm\")\n",
    "  )\n",
    "\n",
    "# view the plot\n",
    "print(p)\n",
    "ggsave(\"scatterplot_matrix.png\", plot = p, width = 12, height = 12, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Read Presence-Only (Occurence) Data & Bunching for Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 **For unbiased/Gauss kernel/Back Thickening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## 1、Read species PO points\n",
    "shp_path <- \"E:/Working/Sam/Experiment/Data/Gentiana pannonica Scop/Alps/Alps_Thinned_plant_point_800m.shp\"\n",
    "species_points <- st_read(shp_path)\n",
    "species_points_df <- as.data.frame(species_points)\n",
    "# head(species_points_df)\n",
    "\n",
    "# read occ table\n",
    "occ <- species_points_df[, c(\"X\", \"Y\")]\n",
    "\n",
    "## 2、Witholding a 20% sample for testing (k-fold cross-validation)\n",
    "fold <- kfold(occ, k=5)\n",
    "occtrain <- occ[fold != 1, ]\n",
    "occtest <- occ[fold == 1, ]\n",
    "# str(occtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2 For Convex Hull**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Visulization: normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## 1、Read species PO points\n",
    "shp_path <- \"E:/Working/Sam/Experiment/Data/Gentiana pannonica Scop/Alps/Alps_Thinned_plant_point_800m.shp\"\n",
    "species_points <- st_read(shp_path)\n",
    "species_points_df <- as.data.frame(species_points)\n",
    "## 2、Build convex hull\n",
    "species_points_sf <- st_as_sf(species_points, coords = c(\"X\", \"Y\"), crs = 4326)\n",
    "convex_hull <- st_convex_hull(st_union(species_points_sf))\n",
    "## 3、Convert convex hull to SpatialPolygons\n",
    "convex_hull_sp <- as(convex_hull, \"Spatial\")\n",
    "## 4、Visulize the convex hull and species points\n",
    "plot(convex_hull_sp, col = 'lightblue')\n",
    "plot(as(species_points_sf, \"Spatial\"), add = TRUE, col = 'red')\n",
    "## 5、Extract species points in convex hull\n",
    "pin_convex_hull <- st_within(species_points, convex_hull)\n",
    "pin_convex_hull_logical <- lengths(pin_convex_hull) > 0\n",
    "species_points_in <- species_points[pin_convex_hull_logical, ]\n",
    "species_points_in_df <- as.data.frame(species_points_in)\n",
    "## 6、Witholding a 20% sample for testing (k-fold cross-validation)\n",
    "occ <- species_points_in_df[, c(\"X\", \"Y\")]\n",
    "fold <- kfold(occ, k = 5)\n",
    "occtrain <- occ[fold != 1, ]\n",
    "occtest <- occ[fold == 1, ]\n",
    "str(occtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Visulization: ggplot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## ggplot2 visualization\n",
    "# convert convex hull to data frame\n",
    "convex_hull_df <- as.data.frame(st_coordinates(convex_hull))\n",
    "colnames(convex_hull_df) <- c(\"longitude\", \"latitude\")\n",
    "\n",
    "# convert PO points to data frame\n",
    "species_points_df <- as.data.frame(st_coordinates(species_points_sf))\n",
    "colnames(species_points_df) <- c(\"longitude\", \"latitude\")\n",
    "\n",
    "# visualize\n",
    "ggplot() +\n",
    "  geom_point(data = species_points_df, aes(x = longitude, y = latitude), color = 'red', size = 2, alpha = 0.6) +\n",
    "  geom_polygon(data = convex_hull_df, aes(x = longitude, y = latitude), fill = 'lightblue', alpha = 0.4) +\n",
    "  coord_equal() +\n",
    "  labs(title = \"Species Occurrence Points within Convex Hull\",\n",
    "       x = \"Longitude\", y = \"Latitude\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Model Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## figure save path ##\n",
    "save_folder= \"E:/Working/Sam/Experiment/Figures/bg points/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unbiased 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## bg_num=2500 ##\n",
    "ex_name<-'unbiased_2500'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "set.seed(123) # random seed for reproducibility\n",
    "bg_num <- 2500\n",
    "bg_points <- randomPoints(predictors, bg_num)\n",
    "bg_points_df <- as.data.frame(bg_points)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Unbiased 2500 Background Points\",cex.main = 1.3)\n",
    "points(bg_points_df$X, bg_points_df$Y, col = 'red', pch = 20,cex=0.5)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,18), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unbiased 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## bg_num=5000 ##\n",
    "ex_name<-'unbiased_5000'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "set.seed(123)\n",
    "bg_num <- 5000\n",
    "bg_points <- randomPoints(predictors, bg_num)\n",
    "bg_points_df <- as.data.frame(bg_points)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Unbiased 5000 Background Points\")\n",
    "points(bg_points_df$X, bg_points_df$Y, col = 'red', pch = 20,cex=0.4)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,20), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unbiased 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## bg_num=10000 ##\n",
    "ex_name<-'unbiased_10000'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "set.seed(123)\n",
    "bg_num <- 10000\n",
    "bg_points <- randomPoints(predictors, bg_num)\n",
    "bg_points_df <- as.data.frame(bg_points)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Unbiased 10000 Background Points\")\n",
    "points(bg_points_df$X, bg_points_df$Y, col = 'red', pch = 20,cex=0.3)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,20), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Biased convex hull 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## covex-hull bg_num=5000 ##\n",
    "ex_name<-'convex_hull_5000'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "set.seed(123)\n",
    "bg_num <- 5000\n",
    "bg_points <- randomPoints(predictors, bg_num, ext = convex_hull_sp)\n",
    "bg_points_df <- as.data.frame(bg_points)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Convex Hull 5000 Background Points\")\n",
    "points(bg_points_df$X, bg_points_df$Y, col = 'red', pch = 20,cex=0.3)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,20), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Biased Gkernel 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Target group sampling bg_num=5000 ##\n",
    "bias_file_path <- \"E:/Working/Sam/Experiment/Results/TargetGroupSampling/gkernel_800m_v2.asc\"\n",
    "bias_raster <- raster(bias_file_path)\n",
    "ex_name<-'Gkernel_5000_v2'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "\n",
    "## generate background points based on bias\n",
    "set.seed(123)\n",
    "bg_num <- 5000\n",
    "bias_vals <- getValues(bias_raster)\n",
    "bias_vals[is.na(bias_vals)] <- 0  # set NA to 0\n",
    "\n",
    "# use 'prob=' to introduce bias\n",
    "sample_cells <- sample(1:length(bias_vals), bg_num, prob = bias_vals, replace = TRUE)\n",
    "bg_coords <- xyFromCell(bias_raster, sample_cells)\n",
    "bg_points_df <- as.data.frame(bg_coords)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Background Points with Target Group Sampling\")\n",
    "points(bg_points_df$X, bg_points_df$Y, col = 'red', pch = 20,cex=0.5)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,20), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Biased Background Thickening 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Background thickening bg_num=5000 ##\n",
    "ex_name<-'BackgroundThickening_5000'\n",
    "full_path<-paste0(save_folder,ex_name,\".tif\")\n",
    "library(gstat)\n",
    "## 1. read predictors\n",
    "temp_tif_folder_path <- c(\"E:/Working/Sam/Experiment/Data/BTfolder\") # With low-resolution to speed up\n",
    "fnames <- lapply(temp_tif_folder_path, function(folder_path) {\n",
    "  list.files(path = folder_path, pattern = '\\\\.tif$', full.names = TRUE, recursive = TRUE)\n",
    "})\n",
    "fnames <- unlist(fnames)\n",
    "if (length(fnames) == 0) {\n",
    "  stop(\"No .tif files found in this folder! Please check the folder path.\")\n",
    "}\n",
    "## 2. Use 'stack' to stack all the grids\n",
    "predictors_temp <- stack(fnames)\n",
    "# plot(predictors_temp)\n",
    "\n",
    "## 3. get var(predictor) names\n",
    "var_names <- names(predictors_temp)\n",
    "## 4. calculate the variogram range\n",
    "variogram_ranges <- numeric(length(var_names))\n",
    "print(\"Starting variogram range calculation...\")\n",
    "# loop through each var\n",
    "for (i in seq_along(var_names)) {\n",
    "  # get var\n",
    "  var <- var_names[i]\n",
    "  # print(paste(\"Processing variable:\", var, \"(\", i, \"of\", length(var_names), \")\"))\n",
    "  var_data <- values(predictors_temp[[var]])\n",
    "  coords <- coordinates(predictors_temp[[var]])\n",
    "  df <- data.frame(var_data = var_data, x = coords[, 1], y = coords[, 2])\n",
    "\n",
    "  # remove NA values\n",
    "  df <- na.omit(df)\n",
    "\n",
    "  # ensure more than 1 rows\n",
    "  if (nrow(df) > 1) {\n",
    "    vgm_model <- variogram(var_data ~ 1, locations = ~ x + y, data = df)\n",
    "    vgm_fit <- fit.variogram(vgm_model, model = vgm(1, \"Sph\", NA, NA))\n",
    "    range <- ifelse(is.na(vgm_fit$range[2]), max(vgm_model$dist), vgm_fit$range[2]) # range[1:3] contains [nugget, range, and sill]\n",
    "    variogram_ranges[i] <- range\n",
    "  } else {\n",
    "    variogram_ranges[i] <- NA\n",
    "  }\n",
    "}\n",
    "\n",
    "# filter the variogram with absolute <=3, and multiply by 10\n",
    "print(variogram_ranges)\n",
    "variogram_ranges_filtered <- variogram_ranges[abs(variogram_ranges) <= 3] * 50\n",
    "print(variogram_ranges_filtered)\n",
    "\n",
    "# calculate the mean range as 'Thickening radius'\n",
    "thickening_radius <- mean(variogram_ranges_filtered, na.rm = TRUE)\n",
    "print(paste(\"Thickening radius calculated:\", thickening_radius))\n",
    "\n",
    "## --- Finish variogram range calculation --- ##\n",
    "## --- Start background thickening process --- ##\n",
    "\n",
    "## 5. create bg points\n",
    "# bg_num=5000（ratio≈0.65）\n",
    "set.seed(123)\n",
    "bg_num <- 8000\n",
    "# restrict bg points to the extent of the predictor\n",
    "predictor_mask <- predictors[[5]]\n",
    "valid_cells <- !is.na(predictor_mask[])\n",
    "mask_layer <- predictor_mask\n",
    "mask_layer[!valid_cells] <- NA # set invalid cells to NA\n",
    "random_coords <- raster::sampleRandom(mask_layer, size = bg_num, xy = TRUE, sp = TRUE)\n",
    "\n",
    "# calculate the distance from each bg to PO\n",
    "dist_matrix <- spDists(as.matrix(occtrain),coordinates(random_coords), longlat = TRUE)\n",
    "# calculate the weights for bg points\n",
    "weights <- colSums(dist_matrix <= thickening_radius)\n",
    "# print(weights)\n",
    "non_zero_count <- sum(weights != 0) # check non-zero count\n",
    "print(non_zero_count)\n",
    "\n",
    "# select bg points based on weights\n",
    "valid_indices <- which(!is.na(weights) & weights > 0)\n",
    "selected_indices <- sample(valid_indices, size = bg_num, replace = TRUE, prob = weights[valid_indices])\n",
    "bg_points <- coordinates(random_coords)[selected_indices, 1:2]\n",
    "bg_points_df <- as.data.frame(bg_points)\n",
    "colnames(bg_points_df) <- c(\"X\", \"Y\")\n",
    "\n",
    "\n",
    "## 6. visualize\n",
    "tiff(filename = full_path, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predictors[[11]], main = \"Background Points with Thickening\")\n",
    "points(bg_points_df, col = \"red\", pch = 20, cex = 0.5)\n",
    "points(occ, col = \"black\", pch = 1, cex = 0.8)\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\",\"Background Points\"),\n",
    "       col = c(\"black\",\"red\"), pch = c(1,20), pt.cex = c(1.5,1.5))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## figure save path ##\n",
    "save_folder= \"E:/Working/Sam/Experiment/Figures/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## model training in Alps: shared by all strategies ##\n",
    "full_path_pre<-paste0(save_folder,ex_name,\"_predict.tif\")\n",
    "full_path_roc<-paste0(save_folder,ex_name,\"_roc.tif\")\n",
    "plot_title<-'BR 5000'\n",
    "\n",
    "## Define result folder + Result file name\n",
    "result_folder <- here(\"Results\",ex_name)\n",
    "if (!dir.create(result_folder, showWarnings = FALSE)) {\n",
    "  message(\"Result folder already exists or could not be created\")\n",
    "}\n",
    "predict_file<-file.path(result_folder,\"maxent_prediction.grd\")\n",
    "eval_file<-file.path(result_folder,\"evaluation_results.csv\")\n",
    "\n",
    "## Model Fitting\n",
    "# 'ex_name' has been defined previously to distinguish methods\n",
    "me <- maxent(predictors, occtrain, a = bg_points_df,args=c(\"-J\", \"-P\"),path=result_folder)\n",
    "# me <- maxent(predictors, occtrain, a = bg_points_df, path=result_folder)\n",
    "print(me)\n",
    "# plot(me)\n",
    "response(me)\n",
    "\n",
    "## Prediction in Alps\n",
    "predict_map <- predict(me, predictors, args=c(\"outputformat=raw\"), progress='text', \n",
    "     filename=predict_file,overwrite=TRUE)\n",
    "tiff(filename = full_path_pre, width = 8, height = 6, units = \"in\", res = 400)\n",
    "plot(predict_map,main=plot_title)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Occurrence Points\"),\n",
    "       col = c(\"black\"), pch = c(1), pt.cex = c(1.5))\n",
    "dev.off()\n",
    "\n",
    "## Evaluation\n",
    "bg <- randomPoints(predictors, 5000)\n",
    "# extract prediction values\n",
    "pvtest <- data.frame(extract(predictors, occtest))\n",
    "avtest <- data.frame(extract(predictors, bg))\n",
    "e1 <- evaluate(me, p=pvtest, a=avtest)\n",
    "tiff(filename = full_path_roc, width = 6, height = 6, units = \"in\", res = 400)\n",
    "plot(e1, 'ROC',main=plot_title)\n",
    "legend(\"bottomright\", legend = c(\"Training Data\",\"Random Prediction\"),\n",
    "       col = c(\"red\",\"grey\"), pch = c(15,15), pt.cex = c(1.5,1.5))\n",
    "dev.off()\n",
    "\n",
    "# Save evaluation results as csv\n",
    "eval_results <- data.frame(\n",
    "  AUC = e1@auc,\n",
    "  Correlation = e1@cor,\n",
    "  Kappa = e1@kappa,\n",
    "  TPR = e1@TPR[1],  \n",
    "  FPR = e1@FPR[1]  \n",
    ")\n",
    "write.csv(eval_results, eval_file, row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Model Evaluation in Bohemian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## model validation in Bohemian: shared by all strategies ##\n",
    "\n",
    "full_path_valid<-paste0(save_folder,ex_name,\"_valid.tif\")\n",
    "# define output file name for new area\n",
    "predict_file<-file.path(result_folder,\"bohemian_prediction.grd\")\n",
    "eval_file<-file.path(result_folder,\"bohemian_evaluation.csv\")\n",
    "\n",
    "# predictors in new area\n",
    "tif_folder_path <- \"E:/Working/Sam/Experiment/Data/Bohemian\"\n",
    "fnames <- list.files(path = tif_folder_path, pattern = \"\\\\.tif$\", full.names = TRUE)\n",
    "predictors_new <- stack(fnames)\n",
    "\n",
    "# occurrence points in new area\n",
    "shp_path <- \"E:/Working/Sam/Experiment/Data/Bohemian/Non_Alps_Thinned_plant_point_800m.shp\" \n",
    "species_points <- st_read(shp_path)\n",
    "species_points_df<- as.data.frame(species_points)\n",
    "occ <- species_points_df[, c(\"X\", \"Y\")]\n",
    "\n",
    "# use fitted model to predict in new area\n",
    "predict_map <- predict(me, predictors_new, args=c(\"outputformat=raw\"), progress='text', \n",
    "     filename=predict_file,overwrite=TRUE)\n",
    "tiff(filename = full_path_valid, width = 6, height = 6, units = \"in\", res = 400)\n",
    "plot(predict_map,main=plot_title)\n",
    "points(occ,pch = 1, col = 'black',cex=0.8)\n",
    "# add legends\n",
    "legend(\"bottomright\", legend = c(\"Real Occurrence Points\"),\n",
    "       col = c(\"black\"), pch = c(1), pt.cex = c(1.5))\n",
    "dev.off()\n",
    "\n",
    "# save probabilities on each occ in res_list\n",
    "res_list <- numeric(length = nrow(occ))\n",
    "for (i in 1:nrow(occ)) {\n",
    "  # get corrdinates\n",
    "  point <- occ[i, ]\n",
    "  x <- point$X\n",
    "  y <- point$Y\n",
    "  # get value on point\n",
    "  value <- extract(predict_map, cbind(x, y))\n",
    "  res_list[i] <- value\n",
    "}\n",
    "# calculate mean & compare\n",
    "mean_res <- mean(res_list,na.rm = TRUE)  # mean of occ points\n",
    "mean_value <- mean(predict_map[], na.rm = TRUE) # mean of whole map\n",
    "# print result\n",
    "print(paste(\"Mean value of occurence points: \",mean_res))\n",
    "print(paste(\"Mean value of the whole region: \",mean_value))\n",
    "\n",
    "criteria = mean_res/mean_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
